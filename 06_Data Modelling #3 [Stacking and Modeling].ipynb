{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c919c468",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from omegaconf import DictConfig,OmegaConf\n",
    "conf = OmegaConf.load('config/config.yaml')\n",
    "pic_=conf['config']['pic_']\n",
    "tracking_uri_=conf['config']['tracking_uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe724a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle5 as pickle\n",
    "from catboost import Pool\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score,cohen_kappa_score,roc_auc_score,log_loss\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c3c900",
   "metadata": {},
   "source": [
    "### Get Feature from data corresponded with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7605440",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load_feature\n",
    "fs=[]\n",
    "with open('ml_output/04_05_modeling/feature_selection/fs.pickle', 'rb') as handle:\n",
    "    fs_=pickle.load(handle)\n",
    "    \n",
    "    catboost_params=fs_['catboost-wo_artificial']\n",
    "    fs_cat_wo_na=catboost_params['params.feature_name'].replace('[','').replace(']','').replace('\\'','').replace(' ','').split(',')\n",
    "    fs.extend(fs_cat_wo_na)\n",
    "    catboost_params=fs_['catboost-w_artificial']\n",
    "    fs_cat_w_a=catboost_params['params.feature_name'].replace('[','').replace(']','').replace('\\'','').replace(' ','').split(',')\n",
    "    fs.extend(fs_cat_w_a)\n",
    "    \n",
    "    lgbm_params=fs_['lightgbm-wo_artificial']\n",
    "    fs_lgbm_wo_na=lgbm_params['params.feature_name'].replace('[','').replace(']','').replace('\\'','').replace(' ','').split(',')\n",
    "    fs.extend(fs_lgbm_wo_na)\n",
    "    lgbm_params=fs_['lightgbm-w_artificial']\n",
    "    fs_lgbm_w_a=lgbm_params['params.feature_name'].replace('[','').replace(']','').replace('\\'','').replace(' ','').split(',')\n",
    "    fs.extend(fs_lgbm_w_a)\n",
    "    \n",
    "    rf_params=fs_['randomforest-wo_artificial']\n",
    "    fs_rf_wo_na=rf_params['params.feature_name'].replace('[','').replace(']','').replace('\\'','').replace(' ','').split(',')\n",
    "    fs.extend(fs_rf_wo_na)\n",
    "    rf_params=fs_['randomforest-w_artificial']\n",
    "    fs_rf_w_a=rf_params['params.feature_name'].replace('[','').replace(']','').replace('\\'','').replace(' ','').split(',')\n",
    "    fs.extend(fs_rf_w_a)\n",
    "    \n",
    "    fs=list(dict.fromkeys(fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42f6c8c",
   "metadata": {},
   "source": [
    "### Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2052ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load model\n",
    "model=[]\n",
    "with open('ml_output/04_05_modeling/tuning/model_tuned.pickle', 'rb') as handle:\n",
    "    model=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b5a479",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bbc91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load data\n",
    "data_sample=pd.read_csv(\"gs://bps-gcp-bucket/MLST2023/preprocessing/sample_\"+str(pic_) +\".csv\",sep=',')\n",
    "data_sample=data_sample\n",
    "X=data_sample[fs]\n",
    "y=data_sample[['nama_valid']]\n",
    "    \n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa64db8",
   "metadata": {},
   "source": [
    "### Running Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d08029ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sk_fold=StratifiedKFold(n_splits=5,shuffle=False)\n",
    "experiment_name = \"Modeling and Stacking\"\n",
    "    ## check if the experiment already exists\n",
    "if not mlflow.get_experiment_by_name(experiment_name):\n",
    "        mlflow.create_experiment(name=experiment_name) \n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "mlflow.set_tracking_uri(tracking_uri_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8805628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_estimate(clf,f_select,params):\n",
    "    global valid_x, valid_y,experiment\n",
    "    pred_y=clf.predict(valid_x[f_select])\n",
    "    preds_proba_y=clf.predict_proba(valid_x[f_select])\n",
    "    f1_micro_=f1_score(valid_y, pred_y,average='micro')\n",
    "    log_loss_=log_loss(valid_y,preds_proba_y)\n",
    "    roc_auc_score_=roc_auc_score(valid_y, preds_proba_y, average=\"weighted\", multi_class=\"ovr\")\n",
    "    cohen_kappa_score_=cohen_kappa_score(valid_y, pred_y)\n",
    "    with mlflow.start_run(experiment_id = experiment.experiment_id,\n",
    "                          run_name=params):\n",
    "        mlflow.log_metric(\"f1_score\", np.mean(f1_micro_))\n",
    "        mlflow.log_metric(\"log_loss\", np.mean( log_loss_))\n",
    "        mlflow.log_metric(\"roc_auc\", np.mean(roc_auc_score_))\n",
    "        mlflow.log_metric(\"cohen_kappa\", np.mean(cohen_kappa_score_))\n",
    "        mlflow.log_param('classifier',params)\n",
    "        mlflow.log_param('feature',f_select)\n",
    "        if params[:1]=='c':\n",
    "            mlflow.catboost.log_model(clf, params)\n",
    "        elif params[:1]=='l':\n",
    "            mlflow.lightgbm.log_model(clf, params)\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(clf,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1330e85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "params='catboost_wo_na'\n",
    "clf_estimate(model[params],fs_cat_wo_na,params)\n",
    "\n",
    "params='catboost_w_a'\n",
    "clf_estimate(model[params],fs_cat_w_a,params)\n",
    "\n",
    "params='lightgbm_wo_na'\n",
    "clf_estimate(model[params],fs_lgbm_wo_na,params)\n",
    "\n",
    "params='lightgbm_w_a'\n",
    "clf_estimate(model[params],fs_lgbm_w_a,params)\n",
    "\n",
    "params='lightgbm_wo_na'\n",
    "clf_estimate(model[params],fs_lgbm_wo_na,params)\n",
    "\n",
    "params='randomforest_wo_na'\n",
    "clf_estimate(model[params],fs_rf_wo_na,params)\n",
    "\n",
    "params='randomforest_w_a'\n",
    "clf_estimate(model[params],fs_rf_w_a,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48cb94d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_wo_na_transform=FunctionTransformer(lambda X: X[fs_cat_wo_na])\n",
    "cat_w_a_transform=FunctionTransformer(lambda X: X[fs_cat_w_a])\n",
    "lgbm_wo_na_transform=FunctionTransformer(lambda X: X[fs_lgbm_wo_na])\n",
    "lgbm_w_a_transform=FunctionTransformer(lambda X: X[fs_lgbm_w_a])\n",
    "rf_wo_na_transform=FunctionTransformer(lambda X: X[fs_rf_wo_na])\n",
    "rf_w_a_transform=FunctionTransformer(lambda X: X[fs_rf_w_a])\n",
    "\n",
    "\n",
    "cat_wona_pipe = Pipeline([('transform_cat_wo', cat_wo_na_transform), ('catboost_wo_na', model['catboost_wo_na'])])\n",
    "cat_wa_pipe = Pipeline([('transform_cat_wa', cat_w_a_transform), ('catboost_w_a', model['catboost_w_a'])])\n",
    "\n",
    "lgbm_wona_pipe = Pipeline([('transform_lgbm_wo', lgbm_wo_na_transform), ('lightgbm_wo_na', model['lightgbm_wo_na'])])\n",
    "lgbm_wa_pipe = Pipeline([('transform_lgbm_wa', lgbm_w_a_transform), ('lightgbm_w_a', model['lightgbm_w_a'])])\n",
    "\n",
    "rf_wona_pipe = Pipeline([('transform_rf_wo', cat_wo_na_transform), ('randomforest_wo_na', model['randomforest_wo_na'])])\n",
    "rf_wa_pipe = Pipeline([('transform_rf_wa', cat_w_a_transform), ('randomforest_w_a', model['randomforest_w_a'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b6d21c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=7.151305796714088e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.151305796714088e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.9271723223410593, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.9271723223410593\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.151305796714088e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.151305796714088e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.151305796714088e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.151305796714088e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.9271723223410593, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.9271723223410593\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.151305796714088e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.151305796714088e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.151305796714088e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.151305796714088e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.9271723223410593, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.9271723223410593\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.151305796714088e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.151305796714088e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "sclf_wona=StackingClassifier(estimators=[('cat_wona_pipe',cat_wona_pipe),\n",
    "                              ('lgbm_wona_pipe',lgbm_wona_pipe),\n",
    "                              ('rf_wona_pipe',rf_wona_pipe)\n",
    "                             ],final_estimator=LogisticRegression(),cv=3)\n",
    "sclf_wona.fit(train_x,train_y)\n",
    "params='stacking_wo_na'\n",
    "clf_estimate(sclf_wona,fs,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "becc0ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.00029613011515538563, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00029613011515538563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.47168058736081653, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.47168058736081653\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00029613011515538563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00029613011515538563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00029613011515538563, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00029613011515538563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.47168058736081653, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.47168058736081653\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00029613011515538563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00029613011515538563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00029613011515538563, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00029613011515538563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.47168058736081653, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.47168058736081653\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00029613011515538563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00029613011515538563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "sclf_wa=StackingClassifier(estimators=[('cat_wa_pipe',cat_wa_pipe),\n",
    "                              ('lgbm_wa_pipe',lgbm_wa_pipe),\n",
    "                              ('rf_wa_pipe',rf_wa_pipe)\n",
    "                             ],final_estimator=LogisticRegression(),cv=3)\n",
    "sclf_wa.fit(train_x,train_y)\n",
    "params='stacking_wa'\n",
    "clf_estimate(sclf_wa,fs,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d93819fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=7.151305796714088e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.151305796714088e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.9271723223410593, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.9271723223410593\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.151305796714088e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.151305796714088e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.151305796714088e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.151305796714088e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.9271723223410593, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.9271723223410593\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.151305796714088e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.151305796714088e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.151305796714088e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.151305796714088e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.9271723223410593, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.9271723223410593\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.151305796714088e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.151305796714088e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00029613011515538563, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00029613011515538563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.47168058736081653, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.47168058736081653\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00029613011515538563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00029613011515538563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00029613011515538563, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00029613011515538563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.47168058736081653, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.47168058736081653\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00029613011515538563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00029613011515538563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00029613011515538563, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00029613011515538563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.47168058736081653, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.47168058736081653\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00029613011515538563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00029613011515538563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "sclf_combined=StackingClassifier(estimators=[\n",
    "                              ('cat_wona_pipe',cat_wona_pipe),\n",
    "                              ('lgbm_wona_pipe',lgbm_wona_pipe),\n",
    "                              ('rf_wona_pipe',rf_wona_pipe),\n",
    "                              ('cat_wa_pipe',cat_wa_pipe),\n",
    "                              ('lgbm_wa_pipe',lgbm_wa_pipe),\n",
    "                              ('rf_wa_pipe',rf_wa_pipe)\n",
    "                             ],final_estimator=LogisticRegression(),cv=3)\n",
    "sclf_combined.fit(train_x,train_y)\n",
    "params='stacking_combined'\n",
    "clf_estimate(sclf_combined,fs,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "714d6cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=7.151305796714088e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.151305796714088e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.9271723223410593, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.9271723223410593\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.151305796714088e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.151305796714088e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.00029613011515538563, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00029613011515538563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.47168058736081653, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.47168058736081653\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00029613011515538563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00029613011515538563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.00029613011515538563, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00029613011515538563\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.47168058736081653, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.47168058736081653\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00029613011515538563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00029613011515538563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eclf_wo_na = VotingClassifier(estimators=[('cat_wona_pipe',cat_wona_pipe),\n",
    "                              ('lgbm_wona_pipe',lgbm_wona_pipe),\n",
    "                              ('rf_wona_pipe',rf_wona_pipe)\n",
    "                             ], voting='soft')\n",
    "eclf_wo_na.fit(train_x,train_y)\n",
    "clf_estimate(eclf_wo_na,fs,'voting_wo_na')\n",
    "\n",
    "\n",
    "eclf_wa = VotingClassifier(estimators=[('cat_wa_pipe',cat_wa_pipe),\n",
    "                              ('lgbm_wa_pipe',lgbm_wa_pipe),\n",
    "                              ('rf_wa_pipe',rf_wa_pipe)\n",
    "                             ], voting='soft')\n",
    "eclf_wa.fit(train_x,train_y)\n",
    "clf_estimate(eclf_wa,fs,'voting_wa')\n",
    "\n",
    "\n",
    "eclf_comb = VotingClassifier(estimators=[('cat_wa_pipe',cat_wa_pipe),\n",
    "                              ('lgbm_wa_pipe',lgbm_wa_pipe),\n",
    "                              ('rf_wa_pipe',rf_wa_pipe),\n",
    "                                       ('cat_wona_pipe',cat_wona_pipe),\n",
    "                              ('lgbm_wona_pipe',lgbm_wona_pipe),\n",
    "                              ('rf_wona_pipe',rf_wona_pipe)\n",
    "                             ], voting='soft')\n",
    "eclf_comb.fit(train_x,train_y)\n",
    "clf_estimate(eclf_comb,fs,'voting_comb')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
