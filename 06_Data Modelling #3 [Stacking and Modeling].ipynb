{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c919c468",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "from omegaconf import DictConfig,OmegaConf\n",
    "conf = OmegaConf.load('config/config.yaml')\n",
    "pic_=conf['config']['pic_']\n",
    "tracking_uri_=conf['config']['tracking_uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe724a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle5 as pickle\n",
    "from catboost import Pool\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score,cohen_kappa_score,roc_auc_score,log_loss\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7605440",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load_feature\n",
    "fs=[]\n",
    "with open('ml_output/04_05_modeling/feature_selection/fs.pickle', 'rb') as handle:\n",
    "    fs_=pickle.load(handle)\n",
    "    \n",
    "    catboost_params=fs_['catboost-wo_artificial']\n",
    "    fs_cat_wo_na=catboost_params['params.feature_name'].replace('[','').replace(']','').replace('\\'','').replace(' ','').split(',')\n",
    "    fs.extend(fs_cat_wo_na)\n",
    "    catboost_params=fs_['catboost-w_artificial']\n",
    "    fs_cat_w_a=catboost_params['params.feature_name'].replace('[','').replace(']','').replace('\\'','').replace(' ','').split(',')\n",
    "    fs.extend(fs_cat_w_a)\n",
    "    \n",
    "    lgbm_params=fs_['lightgbm-wo_artificial']\n",
    "    fs_lgbm_wo_na=lgbm_params['params.feature_name'].replace('[','').replace(']','').replace('\\'','').replace(' ','').split(',')\n",
    "    fs.extend(fs_lgbm_wo_na)\n",
    "    lgbm_params=fs_['lightgbm-w_artificial']\n",
    "    fs_lgbm_w_a=lgbm_params['params.feature_name'].replace('[','').replace(']','').replace('\\'','').replace(' ','').split(',')\n",
    "    fs.extend(fs_lgbm_w_a)\n",
    "    \n",
    "    rf_params=fs_['randomforest-wo_artificial']\n",
    "    fs_rf_wo_na=rf_params['params.feature_name'].replace('[','').replace(']','').replace('\\'','').replace(' ','').split(',')\n",
    "    fs.extend(fs_rf_wo_na)\n",
    "    rf_params=fs_['randomforest-wo_artificial']\n",
    "    fs_rf_w_a=rf_params['params.feature_name'].replace('[','').replace(']','').replace('\\'','').replace(' ','').split(',')\n",
    "    fs.extend(fs_rf_w_a)\n",
    "    \n",
    "    fs=list(dict.fromkeys(fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2052ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load model\n",
    "model=[]\n",
    "with open('ml_output/04_05_modeling/tuning/model_tuned.pickle', 'rb') as handle:\n",
    "    model=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bbc91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load data\n",
    "data_sample=pd.read_csv(\"gs://bps-gcp-bucket/MLST2023/preprocessing/sample_\"+str(pic_) +\".csv\",sep=',')\n",
    "data_sample=data_sample\n",
    "X=data_sample[fs]\n",
    "y=data_sample[['nama_valid']]\n",
    "    \n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d08029ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sk_fold=StratifiedKFold(n_splits=5,shuffle=False)\n",
    "experiment_name = \"Modeling and Stacking\"\n",
    "    ## check if the experiment already exists\n",
    "if not mlflow.get_experiment_by_name(experiment_name):\n",
    "        mlflow.create_experiment(name=experiment_name) \n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "mlflow.set_tracking_uri(tracking_uri_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8805628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_estimate(clf,f_select,params):\n",
    "    global valid_x, valid_y,experiment\n",
    "    pred_y=clf.predict(valid_x[f_select])\n",
    "    preds_proba_y=clf.predict_proba(valid_x[f_select])\n",
    "    f1_micro_=f1_score(valid_y, pred_y,average='micro')\n",
    "    log_loss_=log_loss(valid_y,preds_proba_y)\n",
    "    roc_auc_score_=roc_auc_score(valid_y, preds_proba_y, average=\"weighted\", multi_class=\"ovr\")\n",
    "    cohen_kappa_score_=cohen_kappa_score(valid_y, pred_y)\n",
    "    with mlflow.start_run(experiment_id = experiment.experiment_id,\n",
    "                          run_name=params):\n",
    "        mlflow.log_metric(\"f1_score\", np.mean(f1_micro_))\n",
    "        mlflow.log_metric(\"log_loss\", np.mean( log_loss_))\n",
    "        mlflow.log_metric(\"roc_auc\", np.mean(roc_auc_score_))\n",
    "        mlflow.log_metric(\"cohen_kappa\", np.mean(cohen_kappa_score_))\n",
    "        mlflow.log_param('classifier',params)\n",
    "        if params[:1]=='c':\n",
    "            mlflow.catboost.log_model(clf, params)\n",
    "        elif params[:1]=='l':\n",
    "            mlflow.lightgbm.log_model(clf, params)\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(clf,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1330e85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "params='catboost_wo_na'\n",
    "clf_estimate(model[params],fs_cat_wo_na,params)\n",
    "\n",
    "params='catboost_w_a'\n",
    "clf_estimate(model[params],fs_cat_w_a,params)\n",
    "\n",
    "params='lightgbm_wo_na'\n",
    "clf_estimate(model[params],fs_lgbm_wo_na,params)\n",
    "\n",
    "params='lightgbm_w_a'\n",
    "clf_estimate(model[params],fs_lgbm_w_a,params)\n",
    "\n",
    "params='lightgbm_wo_na'\n",
    "clf_estimate(model[params],fs_lgbm_wo_na,params)\n",
    "\n",
    "params='randomforest_wo_na'\n",
    "clf_estimate(model[params],fs_rf_wo_na,params)\n",
    "\n",
    "cat_na=model['randomforest_w_a']\n",
    "clf_estimate(model[params],fs_rf_w_a,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48cb94d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.03465726343276296, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03465726343276296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.0671474959087606, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0671474959087606\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03465726343276296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03465726343276296\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03465726343276296, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03465726343276296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.0671474959087606, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0671474959087606\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03465726343276296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03465726343276296\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03465726343276296, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03465726343276296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.0671474959087606, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0671474959087606\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03465726343276296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03465726343276296\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=1.1494828601499977e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1494828601499977e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.17113215428784745, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.17113215428784745\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1494828601499977e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1494828601499977e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1494828601499977e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1494828601499977e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.17113215428784745, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.17113215428784745\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1494828601499977e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1494828601499977e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1494828601499977e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1494828601499977e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.17113215428784745, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.17113215428784745\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1494828601499977e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1494828601499977e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.03465726343276296, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03465726343276296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.0671474959087606, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0671474959087606\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03465726343276296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03465726343276296\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=1.1494828601499977e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1494828601499977e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.17113215428784745, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.17113215428784745\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1494828601499977e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1494828601499977e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.03465726343276296, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03465726343276296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.0671474959087606, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0671474959087606\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03465726343276296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03465726343276296\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03465726343276296, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03465726343276296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.0671474959087606, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0671474959087606\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03465726343276296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03465726343276296\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03465726343276296, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03465726343276296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.0671474959087606, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0671474959087606\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03465726343276296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03465726343276296\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1494828601499977e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1494828601499977e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.17113215428784745, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.17113215428784745\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1494828601499977e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1494828601499977e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1494828601499977e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1494828601499977e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.17113215428784745, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.17113215428784745\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1494828601499977e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1494828601499977e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1494828601499977e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1494828601499977e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.17113215428784745, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.17113215428784745\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1494828601499977e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1494828601499977e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jupyter-peta_admin/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.03465726343276296, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03465726343276296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.0671474959087606, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0671474959087606\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03465726343276296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03465726343276296\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "estimators_na = [('catboost_wo_na',model['catboost_wo_na']),\n",
    "              ('lightgbm_wo_na',model['lightgbm_wo_na']),\n",
    "              ('randomforest_wo_na',model['randomforest_wo_na'])]\n",
    "clf_na = StackingClassifier(\n",
    "    estimators=estimators_na, final_estimator=LogisticRegression(),cv=3\n",
    "    )\n",
    "clf_na.fit(train_x,train_y)\n",
    "clf_estimate(clf_na,fs,'stacking_wo_na')\n",
    "\n",
    "\n",
    "estimators_a = [('catboost_w_a',model['catboost_w_a']),\n",
    "              ('lightgbm_w_a',model['lightgbm_w_a']),\n",
    "              ('randomforest_w_a',model['randomforest_w_a'])]\n",
    "clf_a = StackingClassifier(\n",
    "    estimators=estimators_a, final_estimator=LogisticRegression(),cv=3\n",
    "    )\n",
    "clf_a.fit(train_x,train_y)\n",
    "clf_estimate(clf_a,fs,'stacking_w_a')\n",
    "\n",
    "eclf_na = VotingClassifier(estimators=estimators_na, voting='soft')\n",
    "eclf_na.fit(train_x,train_y)\n",
    "clf_estimate(eclf_na,fs,'voting_wo_na')\n",
    "\n",
    "eclf_a = VotingClassifier(estimators=estimators_a, voting='soft')\n",
    "eclf_a.fit(train_x,train_y)\n",
    "clf_estimate(eclf_a,fs,'voting_w_a')\n",
    "\n",
    "estimators = [('catboost_wo_na',model['catboost_wo_na']),\n",
    "                   ('lightgbm_wo_na',model['lightgbm_wo_na']),\n",
    "                   ('randomforest_wo_na',model['randomforest_wo_na']),\n",
    "                   ('catboost_w_a',model['catboost_w_a']),\n",
    "                   ('lightgbm_w_a',model['lightgbm_w_a']),\n",
    "                   ('randomforest_w_a',model['randomforest_w_a'])]\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression(),cv=3\n",
    "    )\n",
    "clf.fit(train_x,train_y)\n",
    "clf_estimate(clf,fs,'stacking_combined')\n",
    "\n",
    "eclf = VotingClassifier(estimators=estimators, voting='soft')\n",
    "eclf.fit(train_x,train_y)\n",
    "clf_estimate(eclf,fs,'voting_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f156fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "clf"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
